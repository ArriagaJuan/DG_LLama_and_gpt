{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false,
    "id": "dT9AQwdf8sJK"
   },
   "source": [
    "# Digital Mentor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hideCode": false,
    "id": "Qgo-oaI3JU2u",
    "outputId": "94e8f443-9ef2-4460-a642-3f8229dc08cf"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import api_utils\n",
    "import utils\n",
    "from messages_proceses import interaction\n",
    "from openai import OpenAI\n",
    "from setpathtomedia import seleccion\n",
    "from labs import text_audio\n",
    "from load_image import load_input\n",
    "from env_fire import subir_firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Cargar las variables de entorno\n",
    "eleven_api_key = os.environ.get('ELEVEN_LABS_KEY')\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Verificar si las variables están definidas\n",
    "if not eleven_api_key or not openai_api_key:\n",
    "    print(\"Error: Las variables de entorno no están definidas.\")\n",
    "    exit(1)\n",
    "openai_client = OpenAI(api_key=openai_api_key)\n",
    "openai_model = \"gpt-4\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "hideCode": false,
    "hideOutput": false,
    "id": "vsphzJawLF-f",
    "outputId": "6700a71e-e87e-41a0-b78a-4abae7b7a843"
   },
   "outputs": [],
   "source": [
    "input_video_path, presentation_video_path, goodbye_video_path, results_path = seleccion(personaje='Albert', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_voice_id = text_audio(eleven_api_key,verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Loading lip model\n",
    "model = utils.load_lip_model(device=device)\n",
    "frames,fps=load_input(input_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def mostrar_video_con_texto(prompt: str, modelo_seleccionado: str) -> str:\n",
    "    \"\"\"\n",
    "    Procesa el prompt y el modelo seleccionado para:\n",
    "      1. Obtener la respuesta mediante la función `interaction`\n",
    "      2. Subir el video a Firebase (o servicio similar) a través de `subir_firebase`\n",
    "      3. Combinar el video y los textos en un bloque HTML\n",
    "    \"\"\"\n",
    "    if not prompt:\n",
    "        return \"Por favor, completa ambos campos.\"\n",
    "\n",
    "    # Obtener la respuesta del modelo seleccionado\n",
    "    try:\n",
    "        respuesta = interaction(\n",
    "            prompt,\n",
    "            modelo_seleccionado,\n",
    "            selected_voice_id,\n",
    "            input_video_path,\n",
    "            openai_client,\n",
    "            openai_model,\n",
    "            eleven_api_key,\n",
    "            results_path,\n",
    "            device,\n",
    "            model\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return \"Error en la interacción: {}\".format(e)\n",
    "\n",
    "    # Subir el video y obtener la URL resultante\n",
    "    try:\n",
    "        URL_VIDEO = subir_firebase(results_path)\n",
    "        print(\"URL del video:\", URL_VIDEO)\n",
    "    except Exception as e:\n",
    "        return \"Error al subir el video: {}\".format(e)\n",
    "\n",
    "    # Generar el HTML para el reproductor de video (como en el código anterior)\n",
    "    reproductor_video = \"\"\"<video width=\"640\" height=\"480\" controls autoplay>\n",
    "                            <source src=\"{}\" type=\"video/mp4\">\n",
    "                            Your browser does not support the video tag.\n",
    "                          </video>\"\"\".format(URL_VIDEO)\n",
    "\n",
    "    # Formatear el prompt y la respuesta para mostrarlos en columnas\n",
    "    prompt_text = '<div style=\"float:left; padding-right:20px;\">{}</div>'.format(prompt.replace(\"\\n\", \"<br>\"))\n",
    "    respuesta_text = '<div style=\"float:right; padding-left:20px;\">{}</div>'.format(respuesta.replace(\"\\n\", \"<br>\"))\n",
    "\n",
    "    # Combinar el reproductor de video y los textos en un contenedor HTML\n",
    "    contenido = '<div style=\"overflow:auto;\">{}<br>{}<br>{}</div>'.format(reproductor_video, prompt_text, respuesta_text)\n",
    "    \n",
    "    return contenido\n",
    "\n",
    "# Crear la interfaz de Gradio con los elementos de entrada y salida\n",
    "interfaz = gr.Interface(\n",
    "    fn=mostrar_video_con_texto,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Pregunta\"),\n",
    "        gr.Radio([\"GPT API\", \"Llama 1B\", \"Llama 3B\"], label=\"Selecciona el modelo de lenguaje\")\n",
    "    ],\n",
    "    outputs=\"html\",\n",
    "    title=\"Mentores Digitales\",\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "\n",
    "interfaz.launch()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "prompt = ''\n",
    "\n",
    "# Archivo para guardar resultados\n",
    "excel_file = \"test_resultssinGan.xlsx\"\n",
    "\n",
    "# URL fija del video\n",
    "def mostrar_video_con_texto(prompt, modelo_seleccionado):\n",
    "    if not prompt:\n",
    "        return \"Por favor, completa ambos campos.\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Pasar el modelo seleccionado a la función `interaction`\n",
    "    respuesta = interaction(prompt, modelo_seleccionado, selected_voice_id, input_video_path, openai_client, openai_model, eleven_api_key, results_path, device, model)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Guardar resultados en un archivo Excel\n",
    "    df = pd.DataFrame({\n",
    "        \"Pregunta\": [prompt],\n",
    "        \"Modelo\": [modelo_seleccionado],\n",
    "        \"Respuesta\": [respuesta],\n",
    "        \"Tiempo (s)\": [end_time - start_time]\n",
    "    })\n",
    "\n",
    "    if not os.path.exists(excel_file):\n",
    "        df.to_excel(excel_file, index=False)\n",
    "    else:\n",
    "        existing_data = pd.read_excel(excel_file)\n",
    "        updated_data = pd.concat([existing_data, df], ignore_index=True)\n",
    "        updated_data.to_excel(excel_file, index=False)\n",
    "\n",
    "    return f\"Tiempo: {end_time - start_time:.2f} segundos. Respuesta guardada en {excel_file}\"\n",
    "\n",
    "# Pruebas automáticas con preguntas relacionadas a Albert Einstein\n",
    "modelos = [\"GPT API\", \"Llama 1B\", \"Llama 3B\"]\n",
    "preguntas = [\n",
    "    \"¿Quién fue Albert Einstein?\",\n",
    "    \"¿Cuáles fueron los logros más importantes de Albert Einstein?\",\n",
    "    \"¿Qué es la teoría de la relatividad?\",\n",
    "    \"¿En qué año Albert Einstein ganó el Premio Nobel de Física?\",\n",
    "    \"¿Cuál fue la contribución de Einstein a la física cuántica?\",\n",
    "    \"¿Qué relación tuvo Albert Einstein con la bomba atómica?\",\n",
    "    \"¿Dónde nació Albert Einstein?\",\n",
    "    \"¿Qué decía Einstein sobre la naturaleza del universo?\",\n",
    "    \"¿Cuál era la filosofía de Albert Einstein sobre la educación?\",\n",
    "    \"¿Qué frases célebres dijo Albert Einstein?\"\n",
    "]\n",
    "\n",
    "def ejecutar_pruebas_automaticas():\n",
    "    for modelo in modelos:\n",
    "        for pregunta in preguntas:\n",
    "            mostrar_video_con_texto(pregunta, modelo)\n",
    "\n",
    "    print(f\"Pruebas completadas. Resultados guardados en {excel_file}\")\n",
    "\n",
    "# Ejecución automática de pruebas\n",
    "if __name__ == \"__main__\":\n",
    "    ejecutar_pruebas_automaticas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "MD_AGENTE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
